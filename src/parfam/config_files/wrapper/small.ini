[META]
model_parameter_search = Complete
; Either 'No', 'Max', 'Complete', 'pretrained', 'pretrained+full'
separate_test_set = True

[MODELPARAMETERS]
max_deg_input = 2
max_deg_output = 2
max_deg_input_denominator = 1
max_deg_output_denominator = 1
max_deg_output_polynomials_specific = [1, 1, 1]
max_deg_output_polynomials_denominator_specific = [1, 1, 1]
width = 1
function_names = ['sqrt', 'cos', 'exp']
maximal_potence = 3
maximal_n_functions = 1

[MODELPARAMETERSFIX]
degree_input_polynomials = 2
degree_output_polynomials = 2
degree_input_denominator = 0
degree_output_denominator = 0
degree_output_polynomials_specific = [1, 1]
degree_output_polynomials_denominator_specific = [1, 1]
width = 1
function_names = ['sin', 'sqrt']
enforce_function = False
maximal_potence = 3

[TRAININGPARAMETERS]
##### General
normalization = False
time_limit = 100
evaluations_limit = 1000000
max_dataset_length = 500
model = 'ParFamTorch'
; ParFamTorch, udsr, pysr, aifeynman, endtoend, dgsr
target_noise = 0.0
feature_noise = 0.0
seed = 1234
accuracy = 0.0001
##### ParFamTorch
maxiter1 = 100
maxiter2 = 0
optimizer : 'basinhopping'
; ['basinhopping', 'differential_evolution', 'dual_annealing', 'bfgs', 'lbfgs']
pruning_iterations = 1
pruning_cut_off = 0.01
classifier : None
local_minimizer = 'BFGS'
maxiter_per_dim_local_minimizer = 100
lambda_1 = 0.001
repetitions = 1
parallel = False
n_processes = 4
lambda_1_cut = 0
lambda_1_piecewise = 0
device = 'cpu'
iterative_finetuning = True
max_n_active_parameters = 10
lambda_1_finetuning = 0.00001
path_pretrained = 'Flexible dimension/full_19_big_training_sets/20240427_070711_5M/Datetime_20240427_070717_Loss_training_set_size_797545_batch_size_341_hidden_dim_256.pt'
topk_predictions = 10
enforce_function_iterate = 'False'
; True, False, or Both