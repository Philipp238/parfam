[META]
results_path = trainingOnSyntheticData/results/
data_path = /home/groups/ai/anonymous/dlparfam/data/
experiment_name = train_model_parameters
objective = model_parameters

[TRAININGPARAMETERS]
resume_training = 'trainingOnSyntheticData/results/Flexible dimension/full_19_big_training_sets/20240427_070711_5M/Datetime_20240427_070717_Loss_training_set_size_797545_batch_size_341_hidden_dim_256.pt'
embedding = ['no']
; no, linear, linear-relu, linear-relu-linear 
dim_embedding = None # dimension of the embedding
dim_hidden_embedding = None # dimension of the hidden layer in the embedding network; will only be used if embedding='linear-relu-linear'
hidden_dim = [256]
batch_size =  [512]
num_inds = [128]
num_layers_enc = [8]
num_layers = [6]
n_epochs = [10000]
loss = 'CE'
early_stopping = 20
gamma_neg = 1
p_target = 0
model = 'set-transformer'
;set-transformer, mlp
n_head = [4]
dropout = [0.0]
init = 'default'  # he, xavier, default
num_layers_classifier = [4]
sab_in_output = [False]
learning_rate = [0.0001]
num_example_predictions = 3
balanced_loss = False
lr_schedule = 'step'
; 'no', 'warm-up', 'step'
warmup_steps = [10000]
one_hot = True
alpha_label_smoothing = 0.0
optimizer = 'adam'
gradient_clipping = 1.0
layer_normalization = True
plt_activations = False
curriculum_learning = False
data_device = ['cpu'] # cpu or cuda (if available)
data_loader_pin_memory = [False]  # Must be False if data_device='cuda' 
data_loader_num_workers = [0]
distributed_training = False

[DATAPARAMETERS]
generate_new_data = False
dataset = ['20240507_114222_full_19_1M_noise', '20240507_180431_full_19_1M_noise', '20240507_180433_full_19_1M_noise', '20240507_190223_full_19_1M_noise', '20240508_090657_full_19_1M_noise']
; '20240424_163605_full_19_100K' 
; ['20240507_114222_full_19_1M_noise', '20240507_180431_full_19_1M_noise', '20240507_180433_full_19_1M_noise', '20240507_190223_full_19_1M_noise', '20240508_090657_full_19_1M_noise']
; ['20240425_215158_full_19_1M', '20240425_215203_full_19_1M',  '20240425_215339_full_19_1M', '20240425_215340_full_19_1M',  '20240425_215349_full_19_1M', '20240426_092508_full_19_1M',  '20240427_120003_full_19_1M', '20240427_115707_full_19_1M',  '20240427_120005_full_19_1M']
training_set_size = [1000000]
test_set_size = 10000
validation_set_size = 10000
degree_input_numerator = 2
degree_input_denominator = 2
degree_output_numerator = 4
degree_output_denominator = 3
width = 1

ensure_uniqueness = False
normalization = ['DataSetWiseXY-11']
; 'DataSetWiseXY-11', 'DataSetWise'
n_functions_max = 1
num_samples_min = 200
num_samples_max = 200
function_names_str = ['cos', 'sqrt', 'exp']
num_visualizations = 0
flexible_dim = True
d_min = 1
d_max = 9
maximal_potence = 3
enforce_function = False
most_complex_function = True
;Generate the function such that for each model parameter setting the "most complicated function" is generated,
; i.e., full use of the degrees and function specified
singularity_free_domain = True
param_distribution = 'gaussian'
enforce_training_set_size = False # should only be used for debugging
predict_only_function = False
use_fisher_yates_shuffle = [False]
target_noise = 0.01
